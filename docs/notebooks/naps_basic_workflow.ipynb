{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "SDq-1wfhRBWs"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/kocherlab/naps/blob/main/docs/notebooks/naps_basic_workflow.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "__EV0njV4R2-"
   },
   "source": [
    "# Notebook: Example NAPS usage"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "LlV70jDuWzea"
   },
   "source": [
    "In this notebook we'll install NAPS, pull the example data from the [GitHub repository](https://github.com/kocherlab/naps), and run `naps-track` against it.\n",
    "\n",
    "This repo is particularly useful in combination with SLEAP's example notebook on remote training and inference which can be found [here](https://colab.research.google.com/github/talmolab/sleap/blob/main/docs/notebooks/Training_and_inference_on_an_example_dataset.ipynb)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "yX9noEb8m8re"
   },
   "source": [
    "## Install NAPS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DUfnkxMtLcK3"
   },
   "outputs": [],
   "source": [
    "!pip install git+https://github.com/kocherlab/naps"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**NOTE**\n",
    "\n",
    "Some problems may occur when installing opencv because of a conflict between SLEAP and NAPS. To fix this, run the cell below.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2imnIw6QWa1z"
   },
   "outputs": [],
   "source": [
    "# If you have a model and want to do the inference on Colab, this can be done quite directly! Just upload your model and run inference as below.\n",
    "# You can also take advantage of the GPU accessibility of Colab to train as well. Look to the SLEAP tutorials for more info.\n",
    "# The models used for these videos can be found at https://doi.org/10.34770/6t6b-9545\n",
    "\n",
    "# !sleap-track example.mp4 -o example-testing.slp -m naps_data/sleap-models/centroid -m naps_data/sleap-models/centered_instance --verbosity json --batch_size 1 --tracking.tracker simple --tracking.similarity iou --tracking.post_connect_single_breaks 1 --tracking.pre_cull_to_target 50 --tracking.target_instance_count 50 --tacking.clean_instance_count 50 --gpu 0"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "iq7jrgUksLtR"
   },
   "source": [
    "## Download sample training data into Colab\n",
    "Let's download a sample dataset from the the NAPS repository.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GBUTQ2Cm44En"
   },
   "outputs": [],
   "source": [
    "!wget https://github.com/kocherlab/naps/raw/main/docs/notebooks/example_data/example.slp\n",
    "!wget https://github.com/kocherlab/naps/raw/main/docs/notebooks/example_data/example.analysis.h5\n",
    "!wget https://github.com/kocherlab/naps/raw/main/docs/notebooks/example_data/example.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oaiFu3s3HVcH"
   },
   "outputs": [],
   "source": [
    "!ls -lht"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "nIsKUX661xFK"
   },
   "source": [
    "## NAPS tracking\n",
    "Now let's track the files using `naps-track`. We've adjusted a couple params here to make the tracks nicer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bi4ksVdCKbBc"
   },
   "outputs": [],
   "source": [
    "!naps-track --slp-path example.slp --video-path example.mp4 --tag-node-name tag --start-frame 0 --end-frame 1200 --aruco-marker-set DICT_5X5_50 --aruco-crop-size 50 --output-path example-naps.slp --aruco-error-correction-rate 0.6 --aruco-adaptive-thresh-constant 7 --aruco-adaptive-thresh-win-size-max 23 --aruco-adaptive-thresh-win-size-step 10 --aruco-adaptive-thresh-win-size-min 3 --half-rolling-window-size 20"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "BXDLsB7tKRZ_"
   },
   "source": [
    "## Download\n",
    "\n",
    "Now we can just download the output! This pulls the video, the output file, and the original project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ej2it8dl_BO_"
   },
   "outputs": [],
   "source": [
    "# Zip the video and output\n",
    "!zip -0 -r naps_output.zip example.mp4 example.slp example-naps.slp\n",
    "\n",
    "# Download\n",
    "from google.colab import files\n",
    "files.download(\"/content/naps_output.zip\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "7Fy26NVmCWFw"
   },
   "source": [
    "If you happen to not be using Chrome, you may get an error here. If that happens, you should be able to download the files using the \"Files\" tab on the left side panel."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "id": "ERsPYhzbx4GR"
   },
   "source": [
    "## After NAPS\n",
    "\n",
    "### SLEAP GUI\n",
    "\n",
    " To view the tracks, open SLEAP (`sleap-label`) and open the resulting SLEAP files directly. The track names will correspond with ArUco tags. If you want to remove individuals without identified tags, simply remove all instances not assigned to a track (custom instance delete)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sleap-convert example-naps.slp -o example-naps.analysis.h5 --format analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nmlycvykyc_2"
   },
   "outputs": [],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "filename = \"example-naps.analysis.h5\"\n",
    "\n",
    "with h5py.File(filename, \"r\") as f:\n",
    "    dset_names = list(f.keys())\n",
    "    locations = f[\"tracks\"][:].T\n",
    "    track_names = f[\"track_names\"][:]\n",
    "    node_names = [n.decode() for n in f[\"node_names\"][:]]\n",
    "\n",
    "print(\"===filename===\")\n",
    "print(filename)\n",
    "print()\n",
    "\n",
    "print(\"===HDF5 datasets===\")\n",
    "print(dset_names)\n",
    "print()\n",
    "\n",
    "print(\"===locations data shape===\")\n",
    "print(locations.shape)\n",
    "print()\n",
    "\n",
    "print(\"===first 5 track names===\")\n",
    "for i, name in enumerate(track_names[0:5]):\n",
    "    print(f\"{i}: {name}\")\n",
    "print()\n",
    "\n",
    "print(\"===nodes===\")\n",
    "for i, name in enumerate(node_names):\n",
    "    print(f\"{i}: {name}\")\n",
    "print()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rendering with sleap-render\n",
    "Now we can simply render this as a video using `sleap-render`. We'll use --frames to subset the frames to render and --tracks to render the tracks. We'll also use --output to specify the output file name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!sleap-render example-naps.slp --frames 550-650 --crop 3664,1024 -o example-naps-tracks.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML\n",
    "from base64 import b64encode\n",
    " \n",
    "def show_video(video_path, video_width = 600):\n",
    "   \n",
    "  video_file = open(video_path, \"r+b\").read()\n",
    " \n",
    "  video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
    "  return HTML(f\"\"\"<video width={video_width} controls><source src=\"{video_url}\"></video>\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_video(\"example-naps-tracks.mp4\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "background_execution": "on",
   "collapsed_sections": [],
   "name": "naps_basic_workflow",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3.7.11 ('sleap_dev')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "177c836934b6a63d57a075b5cc3f7812a3de8a98495a556647184ecb20fdf5fb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
